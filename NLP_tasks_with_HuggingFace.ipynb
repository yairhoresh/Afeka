{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRVlI2EACLEb"
   },
   "source": [
    "### Sentimant *analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FE6LfyJNCHMx",
    "outputId": "217f8ec2-ed6e-49ba-9675-8bc434c5f26a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998656511306763},\n",
       " {'label': 'NEGATIVE', 'score': 0.9991129040718079},\n",
       " {'label': 'POSITIVE', 'score': 0.9985570311546326}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/blog/sentiment-analysis-python\n",
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "data = [\"I love you\", \"I hate you\", \"I don't hate you\"]\n",
    "sentiment_pipeline(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JW19KRKIGJpm"
   },
   "source": [
    "### Fill masked word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "npsrYNNjCgOg",
    "outputId": "3d2ad35d-f0b0-4d50-d832-3c360c4b1b49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.35214367508888245,\n",
       "  'token': 2388,\n",
       "  'token_str': 'mother',\n",
       "  'sequence': 'the mother worked as a nurse.'},\n",
       " {'score': 0.19612574577331543,\n",
       "  'token': 2450,\n",
       "  'token_str': 'woman',\n",
       "  'sequence': 'the woman worked as a nurse.'},\n",
       " {'score': 0.11655837297439575,\n",
       "  'token': 2684,\n",
       "  'token_str': 'daughter',\n",
       "  'sequence': 'the daughter worked as a nurse.'},\n",
       " {'score': 0.0653347596526146,\n",
       "  'token': 2611,\n",
       "  'token_str': 'girl',\n",
       "  'sequence': 'the girl worked as a nurse.'},\n",
       " {'score': 0.025741584599018097,\n",
       "  'token': 2564,\n",
       "  'token_str': 'wife',\n",
       "  'sequence': 'the wife worked as a nurse.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/bert-base-uncased\n",
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "unmasker(\"The [MASK] worked as a nurse.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "De7jruQaD7aC"
   },
   "source": [
    "### Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEXOnreiENXy",
    "outputId": "d93f6089-f042-43f8-c945-e546011dcbf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'anger', 'score': 0.0012407628819346428},\n",
       "  {'label': 'disgust', 'score': 0.0010925332317128778},\n",
       "  {'label': 'fear', 'score': 0.0026731020770967007},\n",
       "  {'label': 'joy', 'score': 0.003078761510550976},\n",
       "  {'label': 'neutral', 'score': 0.004846677184104919},\n",
       "  {'label': 'sadness', 'score': 0.9228119850158691},\n",
       "  {'label': 'surprise', 'score': 0.06425615400075912}]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/j-hartmann/emotion-english-distilroberta-base\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "classifier(\"I'm so sad it happen so suddenly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYOhuJbOIKIm"
   },
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEfd3Td3INxA",
    "outputId": "9bade88c-6e6a-4ae7-ee3d-c38e29e4aac5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Teach NLP is fun but not too taxing. (It has several different versions) If your game needs some of this stuff, you can simply'},\n",
       " {'generated_text': 'Teach NLP is fun but you should stick to what you learn (if at all). If you are going for a solid reading for more than'},\n",
       " {'generated_text': \"Teach NLP is fun but doesn't have the benefits of the traditional approach, so you can use it to learn and apply different lessons. There\"}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/tasks/text-generation\n",
    "\n",
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation', model = 'gpt2')\n",
    "generator(\"Teach NLP is fun but\", max_length = 30, num_return_sequences=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yHIHjieJ_QU"
   },
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24Ih7_hMKCv-",
    "outputId": "7ca01021-7bbf-4d79-daac-cefcea11c24b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is great, isn't it?\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/facebook/wmt19-ru-en\n",
    "from transformers import FSMTForConditionalGeneration, FSMTTokenizer\n",
    "mname = \"facebook/wmt19-ru-en\"\n",
    "tokenizer = FSMTTokenizer.from_pretrained(mname)\n",
    "model = FSMTForConditionalGeneration.from_pretrained(mname)\n",
    "\n",
    "input = \"Машинное обучение - это здорово, не так ли?\"\n",
    "input_ids = tokenizer.encode(input, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids)\n",
    "decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(decoded) # Machine learning is great, isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tw6xgxqTK901"
   },
   "source": [
    "### Textual similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hyBacTGLCKw",
    "outputId": "81280ed7-fb05-45fb-f270-465c510b6a55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04837986 -0.0533237   0.06084255  0.04996348 -0.060212    0.01169236\n",
      "  0.04848676 -0.01432638  0.095245    0.07374042  0.07201275 -0.05591025\n",
      "  0.01506545  0.03981534  0.04570967  0.02327511 -0.03039946  0.02192825\n",
      "  0.02251742 -0.02904169]\n",
      "[ 0.07268582 -0.04635467  0.04954236  0.03125549 -0.04810524 -0.03360383\n",
      "  0.06530692 -0.00248521  0.00512836  0.00185334  0.02351316 -0.06234325\n",
      " -0.00241587  0.05230791  0.03587196 -0.01304413 -0.08356059 -0.02128224\n",
      " -0.04514851 -0.04367592]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99999994, 0.49218965, 0.14639582],\n",
       "       [0.49218965, 0.99999976, 0.07366706],\n",
       "       [0.14639582, 0.07366706, 1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"I like dogs and puppies\", \"I have cats\", 'moon exploration']\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings[0][0:20])\n",
    "print(embeddings[1][0:20])\n",
    "cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUhsKi2tCUdn"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLP_tasks_with_HuggingFace.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
